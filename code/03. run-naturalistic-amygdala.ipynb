{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2509bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined variables\n",
    "work_dir = '/Users/Tem/Documents/naturalistic-threat-ptsd'\n",
    "nPerms = 10000\n",
    "trim_TRs = 4 #number of TRs to trim from beginning and end of functional scan (separate from hemodynamic adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29844cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import levene, mannwhitneyu\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "from scipy.stats import iqr\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import random\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.stats import rankdata\n",
    "from nltools.data import Adjacency\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from matplotlib import gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605100e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to house naturalistic figures\n",
    "date_string = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "naturalistic_fig_dir = f\"{work_dir}/data/figures/naturalistic-figs-{date_string}\"\n",
    "os.makedirs(naturalistic_fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ef6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movie metadata \n",
    "movie_metadata = pd.read_csv(f\"{work_dir}/data/task/stim-metadata-naturalistic.csv\") \n",
    "movie_metadata['Start_TR'][0] = movie_metadata['Start_TR'][0] + trim_TRs\n",
    "movie_metadata['Stop_TR'][len(movie_metadata) - 1] = movie_metadata['Stop_TR'][len(movie_metadata) - 1] - trim_TRs\n",
    "movie_metadata['Scene_Length'] = movie_metadata['Stop_TR'] - movie_metadata['Start_TR']\n",
    "\n",
    "nScenes = len(movie_metadata)\n",
    "movie_TRs = [list(range(movie_metadata['Start_TR'][i], movie_metadata['Stop_TR'][i])) for i in range(0, nScenes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd8e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural data directory\n",
    "data_dir = f\"{work_dir}/data/neural-naturalistic/amygdala-harvard-oxford-6mm\"\n",
    "\n",
    "# Load ROI labels\n",
    "amygdala_labels = pd.read_csv(f\"{work_dir}/masks/amygdala-harvard-oxford/ROI-labels.csv\")\n",
    "\n",
    "# Load participant data\n",
    "cohort_IDs = pd.read_csv(f\"{work_dir}/data/subs/cohort_IDs.csv\")\n",
    "nCohort = len(cohort_IDs)\n",
    "\n",
    "# Load and visualize symptom data\n",
    "CAPS_data = pd.read_csv(f\"{work_dir}/data/subs/CAPS.csv\")\n",
    "symptom_labels = ['Re-experiencing', 'Avoidance-Numbing', 'Hyperarousal']\n",
    "\n",
    "sns.heatmap(np.corrcoef(CAPS_data[symptom_labels].to_numpy(), rowvar = False), \n",
    "            xticklabels = symptom_labels,\n",
    "            yticklabels = symptom_labels,\n",
    "            annot = True)\n",
    "\n",
    "plt.yticks(rotation = 45)\n",
    "plt.xticks(rotation = 45, rotation_mode = 'anchor', ha = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee7aafb",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that calculates spatial interSC\n",
    "def calc_spatial_interSC(group_data):\n",
    "\n",
    "    nGroup = group_data.shape[2]\n",
    "    \n",
    "    group_ByScene = np.zeros((nVoxels, nScenes, nGroup))\n",
    "\n",
    "    for i in range(0, nScenes):\n",
    "        scene_TRs = (movie_TRs[i])\n",
    "        scene_TRs = [x - 1 for x in scene_TRs] \n",
    "        group_ByScene[:,i,:] = np.mean(group_data[:, scene_TRs, :], axis = 1)\n",
    "    \n",
    "    subs = np.arange(0, nGroup)\n",
    "    group_heldout = np.zeros((nVoxels, nScenes, nGroup))\n",
    "    \n",
    "    for i in subs:\n",
    "        sel_subs = subs[subs!= i]\n",
    "        group_heldout[:, :, i] = np.mean(group_ByScene[:, :, sel_subs], axis = 2)\n",
    "    \n",
    "    if shuffle == 1:\n",
    "        shuff_scene = list(range(nScenes))\n",
    "        random.shuffle(shuff_scene)\n",
    "        group_ByScene = group_ByScene[:, shuff_scene, :] \n",
    "        \n",
    "    full_interSC_group = np.zeros((nScenes, nGroup))\n",
    "    group_median_nonmatch = np.zeros(nGroup)\n",
    "\n",
    "    diag_mask = np.ones((nScenes, nScenes), dtype = bool)\n",
    "    np.fill_diagonal(diag_mask, False)\n",
    "    div_by = len(diag_mask)\n",
    "\n",
    "    for i in range(nGroup):\n",
    "        sub_mat = np.corrcoef(group_ByScene[:,:,i], group_heldout[:,:,i], rowvar = False)\n",
    "        sub_mat = sub_mat[div_by:, :div_by]\n",
    "        full_interSC_group[:, i] = np.diagonal(sub_mat)\n",
    "        group_median_nonmatch[i] = np.median(sub_mat[diag_mask])\n",
    "    \n",
    "    return full_interSC_group, group_ByScene, group_median_nonmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44c25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that correlates an interSC variable with each dimension of a symptom variable\n",
    "def corr_isc_symp(interSC_var, symp_var): \n",
    "    \n",
    "    actual_corrs = [None] * len(symptom_labels)\n",
    "    corr_p_vals = [None] * len(symptom_labels)\n",
    "    all_null_dists = [None] * len(symptom_labels)\n",
    "    \n",
    "    for i in range(len(symptom_labels)):\n",
    "        \n",
    "        which_score = symptom_labels[i]\n",
    "        null_dist = np.zeros(nPerms)\n",
    "\n",
    "        # Actual r value\n",
    "        x = symp_var[which_score]\n",
    "        y = interSC_var\n",
    "        nas = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "        actual_corr = stats.spearmanr(x[~nas], y[~nas])[0]\n",
    "        actual_corrs[i] = actual_corr\n",
    "\n",
    "        # Null dist of r-values \n",
    "        for j in range(nPerms):\n",
    "            x = symp_var[which_score]\n",
    "            y = interSC_var[random.choices(range(nCohort), k = (nCohort))]\n",
    "            nas = np.logical_or(np.isnan(x), np.isnan(y))\n",
    "            null_dist[j] = stats.spearmanr(x[~nas], y[~nas])[0]\n",
    "    \n",
    "        perms_above_frac = len((null_dist[null_dist > actual_corr]) + 1) / (nPerms + 1)\n",
    "        corr_p_vals[i] = min(2*perms_above_frac, 2*(1-perms_above_frac))\n",
    "        all_null_dists[i] = null_dist\n",
    "        \n",
    "    return actual_corrs, corr_p_vals, all_null_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea84ac3",
   "metadata": {},
   "source": [
    "## Matching vs. Non-Matching Scene InterSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51578fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store matching vs. non-matching (MvNM) scene data\n",
    "ROI_MvNM_labels = ['L. Amygdala', 'R. Amygdala']\n",
    "ROI_MvNM_nulls = []\n",
    "ROI_MvNM_actuals = []\n",
    "ROI_MvNM_p_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcc114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load right amygdala data\n",
    "list_LA_data = [None] * nCohort\n",
    "for i in range(nCohort):\n",
    "    list_LA_data[i] = np.load(f\"{data_dir}/HO_1_6mm/{cohort_IDs['subject'][i]}_6mm.npy\")\n",
    "LA_data = np.stack(list_LA_data, axis = 2)\n",
    "\n",
    "# Compute left amygdala interSC and p-value\n",
    "shuffle = 0\n",
    "nVoxels = LA_data.shape[0]\n",
    "LA_full_interSC, LA_ByScene, LA_nonmatch = calc_spatial_interSC(LA_data)\n",
    "LA_interSC = np.median(LA_full_interSC, axis = 0)\n",
    "\n",
    "actual_diff = np.median(LA_interSC - LA_nonmatch)\n",
    "null_dist_diff = np.zeros(nPerms)\n",
    "\n",
    "shuffle = 1\n",
    "\n",
    "for k in range(nPerms):\n",
    "    shuff_LA_full_interSC, shuff_LA_ByScene, shuff_LA_nonmatch = calc_spatial_interSC(LA_data)\n",
    "    shuff_LA_interSC = np.median(shuff_LA_full_interSC, axis = 0)\n",
    "    \n",
    "    null_dist_diff[k] = np.median(shuff_LA_interSC - shuff_LA_nonmatch)\n",
    "    perms_above_frac = (len(null_dist_diff[null_dist_diff > actual_diff]) + 1) / (nPerms + 1)\n",
    "    p_val_diff = min(2*perms_above_frac, 2*(1-perms_above_frac))\n",
    "\n",
    "print(f\"Diff p-val: {p_val_diff}\")\n",
    "\n",
    "ROI_MvNM_nulls.append(null_dist_diff)\n",
    "ROI_MvNM_actuals.append(actual_diff)\n",
    "ROI_MvNM_p_vals.append(p_val_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb69c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load right amygdala data\n",
    "list_RA_data = [None] * nCohort\n",
    "for i in range(nCohort):\n",
    "    list_RA_data[i] = np.load(f\"{data_dir}/HO_2_6mm/{cohort_IDs['subject'][i]}_6mm.npy\")\n",
    "RA_data = np.stack(list_RA_data, axis = 2)\n",
    "\n",
    "# Compute right amygdala interSC and p-value\n",
    "shuffle = 0\n",
    "nVoxels = RA_data.shape[0]\n",
    "RA_full_interSC, RA_ByScene, RA_nonmatch = calc_spatial_interSC(RA_data)\n",
    "RA_interSC = np.median(RA_full_interSC, axis = 0)\n",
    "\n",
    "actual_diff = np.median(RA_interSC - RA_nonmatch)\n",
    "null_dist_diff = np.zeros(nPerms)\n",
    "\n",
    "shuffle = 1\n",
    "\n",
    "for k in range(nPerms):\n",
    "    shuff_RA_full_interSC, shuff_RA_ByScene, shuff_RA_nonmatch = calc_spatial_interSC(RA_data)\n",
    "    shuff_RA_interSC = np.median(shuff_RA_full_interSC, axis = 0)\n",
    "    \n",
    "    null_dist_diff[k] = np.median(shuff_RA_interSC - shuff_RA_nonmatch)\n",
    "    \n",
    "    perms_above_frac = (len(null_dist_diff[null_dist_diff > actual_diff]) + 1) / (nPerms + 1)\n",
    "    p_val_diff = min(2*perms_above_frac, 2*(1-perms_above_frac))\n",
    "\n",
    "print(f\"Diff p-val: {p_val_diff}\")\n",
    "\n",
    "ROI_MvNM_nulls.append(null_dist_diff)\n",
    "ROI_MvNM_actuals.append(actual_diff)\n",
    "ROI_MvNM_p_vals.append(p_val_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble data into pandas dataframes\n",
    "LA_MvNM_data = pd.DataFrame({'InterSC': list(LA_interSC) + list(LA_nonmatch),\n",
    "                             'ROI': ['L. Amyg'] * (len(LA_interSC)*2),\n",
    "                             'Scene Type': ['Matching'] * len(LA_interSC) + ['Non-Matching'] * len(LA_nonmatch)})\n",
    "\n",
    "RA_MvNM_data = pd.DataFrame({'InterSC': list(RA_interSC) + list(RA_nonmatch),\n",
    "                             'ROI': ['R. Amyg'] * (len(RA_interSC)*2),\n",
    "                             'Scene Type': ['Matching'] * len(RA_interSC) + ['Non-Matching'] * len(RA_nonmatch)})\n",
    "\n",
    "\n",
    "ROI_MvNM_data = pd.concat([LA_MvNM_data, RA_MvNM_data])\n",
    "ROI_MvNM_p_corrected = fdrcorrection(ROI_MvNM_p_vals)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf6931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate medians and IQRs for matching scenes\n",
    "LA_iqr = iqr(LA_interSC)\n",
    "RA_iqr = iqr(RA_interSC)\n",
    "\n",
    "print('Left Amygdala')\n",
    "print(f\"median: {np.median(LA_interSC)}\")\n",
    "print(f\"iqr: {LA_iqr}\")\n",
    "\n",
    "print('\\nRight Amygdala')\n",
    "print(f\"median: {np.median(RA_interSC)}\")\n",
    "print(f\"iqr: {RA_iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate medians and IQRs for non-matching scenes\n",
    "LA_nonmatch_iqr = iqr(LA_nonmatch)\n",
    "RA_nonmatch_iqr = iqr(RA_nonmatch)\n",
    "\n",
    "print('Left Amygdala')\n",
    "print(f\"median: {np.median(LA_nonmatch)}\")\n",
    "print(f\"iqr: {LA_nonmatch_iqr}\")\n",
    "\n",
    "print('\\nRight Amygdala')\n",
    "print(f\"median: {np.median(RA_nonmatch)}\")\n",
    "print(f\"iqr: {RA_nonmatch_iqr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matching vs. non-matching interSC by ROI\n",
    "f = plt.figure(figsize = (9, 7))\n",
    "f.subplots_adjust(wspace = 0.5)\n",
    "\n",
    "plt.subplot(121)\n",
    "ax = sns.boxplot(data = LA_MvNM_data, \n",
    "            x = 'ROI', \n",
    "            y = 'InterSC', \n",
    "            hue = 'Scene Type', \n",
    "            linewidth = 2,\n",
    "            palette = 'Oranges_r')\n",
    "\n",
    "plt.xlabel(None)\n",
    "ax.tick_params(bottom = False)\n",
    "plt.legend([],[], frameon = False)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "ax2 = sns.boxplot(data = RA_MvNM_data, \n",
    "            x = 'ROI', \n",
    "            y = 'InterSC', \n",
    "            hue = 'Scene Type', \n",
    "            linewidth = 2,\n",
    "            palette = 'Oranges_r')\n",
    "\n",
    "plt.xlabel(None)\n",
    "plt.ylabel(None)\n",
    "ax2.tick_params(bottom = False)\n",
    "plt.legend([],[], frameon = False)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/MvNM_isc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6516c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot matching vs non-matching interSC difference against null distribution \n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f.subplots_adjust(wspace = 0.15)\n",
    "\n",
    "plt.subplot(121)\n",
    "ax1 = sns.histplot(data = ROI_MvNM_nulls[0], color = '0.25', element = \"step\", fill = False, linewidth = 3)\n",
    "plt.title(f\"{ROI_MvNM_labels[0]}\\n\", fontsize = 14)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(f\"\\np = {np.round(ROI_MvNM_p_corrected[0], 5)}, corrected\", fontsize = 14)\n",
    "plt.axvline(ROI_MvNM_actuals[0], color = '#CE5214', linewidth = 2.5)\n",
    "plt.axvline(np.mean(ROI_MvNM_nulls[0]), color = '0.5', linestyle = 'dashed', linewidth = 2)\n",
    "ax1.set_yticklabels([0, 100, 200, 300, 400, 500], size = 14)\n",
    "ax1.set_xticklabels(np.round(ax1.get_xticks(), 3), size = 14)\n",
    "\n",
    "plt.subplot(122)\n",
    "ax2 = sns.histplot(data = ROI_MvNM_nulls[1], color = '0.25', element = \"step\", fill = False, linewidth = 3)\n",
    "plt.title(f\"{ROI_MvNM_labels[1]}\\n\", fontsize = 14)\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(f\"\\np = {np.round(ROI_MvNM_p_corrected[1], 5)}, corrected\", fontsize = 14)\n",
    "plt.axvline(ROI_MvNM_actuals[1], color = '#CE5214', linewidth = 2.5)\n",
    "plt.axvline(np.mean(ROI_MvNM_nulls[1]), color = '0.5', linestyle = 'dashed', linewidth = 2)\n",
    "ax2.set_yticklabels([0, 100, 200, 300, 400, 500], size = 14)\n",
    "ax2.set_xticklabels(np.round(ax2.get_xticks(), 3), size = 14)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/isc_histograms.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078d0c04",
   "metadata": {},
   "source": [
    "## Left Amygdala InterSC vs. Symptom Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a054e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Spearman correlations between left amygdala interSC and each CAPS dimension\n",
    "print('Left Amygdala Spatial InterSC vs. Symptoms \\n')\n",
    "nVoxels, nTRs, nCohort = LA_data.shape\n",
    "LA_spatial_r_vals, LA_spatial_p_vals, LA_spatial_nulls =  corr_isc_symp(LA_interSC, CAPS_data)\n",
    "LA_spatial_p_corrected = fdrcorrection(LA_spatial_p_vals)[1]\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "summary['score'] = symptom_labels\n",
    "summary['r_vals'] = LA_spatial_r_vals\n",
    "summary['p_vals'] = LA_spatial_p_vals\n",
    "summary['p_corrected'] = LA_spatial_p_corrected\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f89f74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interSC vs. symptom severity for each CAPS dimension\n",
    "f = plt.figure(figsize=(12, 5))\n",
    "f.suptitle('Left Amygdala Spatial InterSC vs. Symptom Severity', fontsize = 14)\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.25)\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "x = CAPS_data['Hyperarousal']\n",
    "y = LA_interSC\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#BB6110\"}).set(xlabel = '\\nHyperarousal Severity')\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "plt.ylabel('InterSC')\n",
    "\n",
    "ax2 = plt.subplot(132, sharey = ax1)\n",
    "x = CAPS_data['Avoidance-Numbing']\n",
    "y = LA_interSC\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#BB6110\"}).set(xlabel = '\\nAvoidance-Numbing Severity')\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "\n",
    "ax3 = plt.subplot(133, sharey = ax1)\n",
    "x = CAPS_data['Re-experiencing']\n",
    "y = LA_interSC\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#BB6110\"}).set(xlabel = '\\nRe-experiencing')\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/symptom_correlations.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d5a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot null distribution of Spearman coefficients (interSC vs. hyperarousal only)\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f.subplots_adjust(wspace = 0.15)\n",
    "\n",
    "plt.subplot(121)\n",
    "ax = sns.histplot(data = LA_spatial_nulls[2], color = '0.25', element = \"step\", fill = False, linewidth = 3)\n",
    "plt.title(f\"Left Amygdala \\n InterSC vs. {symptom_labels[2]}\\n\", fontsize = 14)\n",
    "plt.xlabel(f\"p = {np.round(LA_spatial_p_corrected[2], 5)}, corrected\", fontsize = 14)\n",
    "plt.axvline(LA_spatial_r_vals[2], color = \"#BB6110\", linewidth = 2.5)\n",
    "plt.axvline(np.mean(LA_spatial_nulls[2]), color = '0.5', linestyle = 'dashed', linewidth = 2)\n",
    "ax.set_yticklabels([0, 100, 200, 300, 400, 500], size = 14)\n",
    "ax.set_xticklabels(np.round(ax.get_xticks(), 3), size = 14)\n",
    "plt.ylabel(None)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/hyperarousal_histogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67126a",
   "metadata": {},
   "source": [
    "# Left Amygdala InterSC by Valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate interSC for neutral scenes and negative scenes separately\n",
    "print('InterSC vs. Symptom Left Amygdala Results by Valence')\n",
    "neu_scenes = (movie_metadata['rMode_Counts'] > 3) & (movie_metadata['rMode'] == 3)\n",
    "neg_scenes = (movie_metadata['rMode_Counts'] > 3) & (movie_metadata['rMode'] > 3)\n",
    "\n",
    "neu_isc = np.median(LA_full_interSC[neu_scenes], axis = 0)\n",
    "neg_isc = np.median(LA_full_interSC[neg_scenes], axis = 0)\n",
    "\n",
    "neu_r, neu_p, neu_null_dists = corr_isc_symp(neu_isc, CAPS_data)\n",
    "neg_r, neg_p, neg_null_dists = corr_isc_symp(neg_isc, CAPS_data)\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "summary['score'] = symptom_labels\n",
    "summary['neu_p'] = neu_p\n",
    "summary['neg_p'] = neg_p\n",
    "summary['neu_r'] = neu_r\n",
    "summary['neg_r'] = neg_r\n",
    "\n",
    "summary = summary[summary['score'].str.match('Hyperarousal')]\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9062c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print number of neutral and negative scenes \n",
    "print(f\"# neutral scenes = {sum(neu_scenes)}\")\n",
    "print(f\"# negative scenes = {sum(neg_scenes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88342feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate interSC vs. hyperarousal severity for neutral scenes and negative scenes separately\n",
    "valence_hyp_p_corrected = fdrcorrection([summary['neu_p'][2], summary['neg_p'][2]])\n",
    "neu_hyp_p_corrected = np.round(valence_hyp_p_corrected[1][0], 5)\n",
    "neg_hyp_p_corrected = np.round(valence_hyp_p_corrected[1][1], 5)\n",
    "\n",
    "# Calculate difference in r value for negative and neutral scenes\n",
    "hyp_neg_r = summary['neg_r'][2]\n",
    "hyp_neu_r = summary['neu_r'][2]\n",
    "actual_val_diff = hyp_neg_r - hyp_neu_r\n",
    "\n",
    "# Generate null distribution of r differences \n",
    "val_scenes = (movie_metadata['rMode_Counts'] > 3) & (movie_metadata['rMode'] >= 3)\n",
    "nVal = val_scenes.sum()\n",
    "val_null_dist = np.zeros(nPerms)\n",
    "\n",
    "for i in range(nPerms):\n",
    "    full_val_index = random.choices(range(nVal), k = (nVal))\n",
    "    val_index1 = full_val_index[:neu_scenes.sum()]\n",
    "    val_index2 = full_val_index[neu_scenes.sum():]\n",
    "\n",
    "    val_shuff1 = np.median(LA_full_interSC[val_index1], axis = 0)\n",
    "    val_shuff2 = np.median(LA_full_interSC[val_index2], axis = 0)\n",
    "\n",
    "    null_r1 = (stats.spearmanr(CAPS_data['Hyperarousal'], val_shuff1)[0])\n",
    "    null_r2 = (stats.spearmanr(CAPS_data['Hyperarousal'], val_shuff2)[0])\n",
    "\n",
    "    val_null_dist[i] = null_r2 - null_r1\n",
    "\n",
    "perms_above_frac = len((val_null_dist[val_null_dist > actual_val_diff]) + 1) / (nPerms + 1)\n",
    "val_p_val = min(2*perms_above_frac, 2*(1-perms_above_frac))\n",
    "val_p_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296214a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interSC vs. hyperarousal severity for neutral scenes and negative scenes separately\n",
    "f = plt.figure(figsize=(9, 5))\n",
    "f.subplots_adjust(wspace = 1)\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "x = CAPS_data['Hyperarousal']\n",
    "y = neg_isc\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#8c0e88\"}).set(\n",
    "    title = f\"Negative Scenes\", ylabel = 'InterSC', xlabel = f\"\\nHyperarousal Severity\\np = {neg_hyp_p_corrected}, corrected\")\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.ylabel(None)\n",
    "\n",
    "\n",
    "ax2 = plt.subplot(122, sharey = ax1)\n",
    "x = CAPS_data['Hyperarousal']\n",
    "y = neu_isc\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#8c0e88\"}).set(\n",
    "    title = f\"Neutral Scenes\", ylabel = 'Spatial InterSC', xlabel = f\"\\nHyperarousal Severity\\np={neu_hyp_p_corrected}, corrected\")\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "plt.yticks(fontsize = 14)\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/valence.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eef276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot null distributions for neutral and negative interSC vs. hyperarousal Spearman's coefficient\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f.subplots_adjust(wspace = 0.15)\n",
    "\n",
    "plt.subplot(121)\n",
    "ax1 = sns.histplot(data = neg_null_dists[2], color = '0.25', element = \"step\", fill = False, linewidth = 3)\n",
    "plt.title(f\"Negative Scenes\\n\", fontsize = 14)\n",
    "plt.ylabel(None)\n",
    "plt.axvline(hyp_neg_r, color = '#8c0e88', linewidth = 2.5)\n",
    "plt.axvline(np.mean(ROI_MvNM_nulls[0]), color = '0.5', linestyle = 'dashed', linewidth = 2)\n",
    "ax1.set_yticklabels([0, 100, 200, 300, 400, 500], size = 14)\n",
    "ax1.set_xticklabels(np.round(ax1.get_xticks(), 3), size = 14)\n",
    "\n",
    "plt.subplot(122)\n",
    "ax2 = sns.histplot(data = neu_null_dists[2], color = '0.25', element = \"step\", fill = False, linewidth = 3)\n",
    "plt.title(f\"Neutral Scenes\\n\", fontsize = 14)\n",
    "plt.ylabel(None)\n",
    "plt.axvline(hyp_neu_r, color = '#8c0e88', linewidth = 2.5)\n",
    "plt.axvline(np.mean(ROI_MvNM_nulls[1]), color = '0.5', linestyle = 'dashed', linewidth = 2)\n",
    "ax2.set_yticklabels([0, 100, 200, 300, 400, 500], size = 14)\n",
    "ax2.set_xticklabels(np.round(ax2.get_xticks(), 3), size = 14)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/valence_histograms.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27650057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot negative Spearman's coefficient and neutral Spearman's coefficient in bar graph\n",
    "f = plt.figure(figsize=(5, 6))\n",
    "x = [0.25, 0.75]\n",
    "y = [hyp_neg_r, hyp_neu_r]\n",
    "sns.barplot(x = x, y = y, color = \"#8c0e88\")\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylabel(f\"Spearman's coefficient \\nInterSC vs. Hyperarousal\\n\", fontsize = 16)\n",
    "sns.despine(top = False, bottom = True)\n",
    "\n",
    "plt.savefig(f\"{naturalistic_fig_dir}/valence_pearsons.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
