{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f804408d",
   "metadata": {},
   "source": [
    "## Inter-subject correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interSC \n",
    "classical_data = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    classical_data[i] = np.load(f\"{npy_dir}/{cROI}_6mm/{cohort_IDs['subject'][i]}_6mm.npy\")\n",
    "\n",
    "nVoxels = classical_data[0].shape[0]\n",
    "classical_patterns = np.zeros((nVoxels, 2, nCohort))\n",
    "\n",
    "for i in range(nCohort):\n",
    "    classical_patterns[:, 0, i] = np.mean(classical_data[i][:, all_CSminus_onsets[i]], axis = 1)\n",
    "    classical_patterns[:, 1, i] = np.mean(classical_data[i][:, all_CSplus_onsets[i]], axis = 1)\n",
    "    \n",
    "subs = np.arange(0, nCohort)\n",
    "classical_heldout = np.zeros_like(classical_patterns)\n",
    "    \n",
    "for i in subs:\n",
    "    sel_subs = subs[subs!= i]\n",
    "    classical_heldout[:, :, i] = np.mean(classical_patterns[:, :, sel_subs], axis = 2)\n",
    "    \n",
    "all_mats = np.zeros((2, 2, nCohort))\n",
    "ROI_interSC = np.zeros((2, nCohort))\n",
    "\n",
    "for i in range(nCohort):\n",
    "    sub_mat = np.corrcoef(classical_patterns[:,:,i], classical_heldout[:,:,i], rowvar = False)\n",
    "    sub_mat = sub_mat[:2, 2:]\n",
    "    all_mats[:,:,i] = sub_mat\n",
    "    ROI_interSC[:, i] = np.diagonal(sub_mat)\n",
    "\n",
    "    \n",
    "threat_control_isc = np.zeros(nCohort)\n",
    "threat_threat_isc = np.zeros(nCohort)\n",
    "\n",
    "for i in range(nCohort):\n",
    "    threat_control_isc[i] = all_mats[:,:,i][1,0]\n",
    "    threat_threat_isc[i] = all_mats[:,:,i][1,1]\n",
    "\n",
    "threat_threat_med = np.median(threat_threat_isc)\n",
    "threat_control_med = np.median(threat_control_isc)\n",
    "\n",
    "threat_threat_iqr = iqr(threat_threat_isc)\n",
    "threat_control_iqr = iqr(threat_control_isc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99dae2",
   "metadata": {},
   "source": [
    "## Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate discrimination\n",
    "diff_scores = np.zeros(nCohort)\n",
    "for i in range(nCohort):\n",
    "    diff_scores[i] = threat_threat_isc[i] - threat_control_isc[i] \n",
    "    logical = diff_scores > 0\n",
    "disc_rate = sum(logical)/nCohort * 100\n",
    "\n",
    "# Generate null distribution\n",
    "null_dist_disc = np.zeros(nPerms)\n",
    "\n",
    "for k in range(nPerms):\n",
    "\n",
    "    all_classical_patterns = np.zeros((nVoxels, 2, nCohort))\n",
    "\n",
    "    for i in range(nCohort):\n",
    "        concat_CS = np.asarray(all_CSminus_onsets[i] + all_CSplus_onsets[i])\n",
    "        break_point = len(all_CSminus_onsets[i])\n",
    "        concat_CS = concat_CS[random.choices(range(len(concat_CS)), k = (len(concat_CS)))]    \n",
    "        all_classical_patterns[:, 0, i] = np.mean(classical_data[i][:, concat_CS[:break_point]], axis = 1)\n",
    "        all_classical_patterns[:, 1, i] = np.mean(classical_data[i][:, concat_CS[break_point:]], axis = 1)\n",
    "\n",
    "    subs = np.arange(0, nCohort)\n",
    "    all_classical_heldout = np.zeros_like(all_classical_patterns)\n",
    "\n",
    "    for i in subs:\n",
    "        sel_subs = subs[subs!= i]\n",
    "        all_classical_heldout[:, :, i] = np.mean(all_classical_patterns[:, :, sel_subs], axis = 2)\n",
    "\n",
    "    all_mats = np.zeros((2, 2, nCohort))\n",
    "\n",
    "    for i in range(nCohort):\n",
    "        sub_mat = np.corrcoef(all_classical_patterns[:,:,i], all_classical_heldout[:,:,i], rowvar = False)\n",
    "        all_mats[:,:,i] = sub_mat[:2, 2:]\n",
    "        \n",
    "    # Classification\n",
    "    diff_scores = np.zeros(nCohort)\n",
    "\n",
    "    for i in range(nCohort):\n",
    "        shuff_threat_control_isc = all_mats[:,:,i][1,0]\n",
    "        shuff_isc_plus = all_mats[:,:,i][1,1]\n",
    "        diff_scores[i] = shuff_isc_plus - shuff_threat_control_isc \n",
    "        logical = diff_scores > 0\n",
    "    \n",
    "    null_dist_disc[k] = (sum(logical)/nCohort * 100)\n",
    "    \n",
    "disc_p_val = len((null_dist_class[null_dist_class > disc_rate]) + 1) / (nPerms + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2900e6",
   "metadata": {},
   "source": [
    "## InterSC vs. Symptom Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that correlates an interSC variable with each dimension of a symptom variable\n",
    "def corr_isc_symp(interSC_var, symp_var): \n",
    "    actual_corrs = [None] * len(symptom_labels)\n",
    "    corr_p_vals = [None] * len(symptom_labels)\n",
    "    all_null_dists = [None] * len(symptom_labels)\n",
    "    \n",
    "    for i in range(len(symptom_labels)):\n",
    "        which_score = symptom_labels[i]\n",
    "        null_dist = np.zeros(nPerms)\n",
    "\n",
    "        # Actual r value\n",
    "        x = symp_var[which_score]\n",
    "        y = interSC_var\n",
    "        actual_corr = stats.spearmanr(x, y)[0]\n",
    "        actual_corrs[i] = actual_corr\n",
    "\n",
    "        # Null dist of r-values \n",
    "        for j in range(nPerms):\n",
    "            x = symp_var[which_score]\n",
    "            y = interSC_var[random.choices(range(nCohort), k = (nCohort))]\n",
    "            null_dist[j] = stats.spearmanr(x, y)[0]\n",
    "    \n",
    "        perms_above_frac = len((null_dist[null_dist > actual_corr]) + 1) / (nPerms + 1)\n",
    "        corr_p_vals[i] = min(2*perms_above_frac, 2*(1-perms_above_frac))\n",
    "        all_null_dists[i] = null_dist\n",
    "        \n",
    "    return actual_corrs, corr_p_vals, all_null_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b27465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate interSC with symptom severity\n",
    "ROI_rho_vals, ROI_p_vals, ROI_nulls =  corr_isc_symp(threat_threat_isc, CAPS_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f5fbbc",
   "metadata": {},
   "source": [
    "## Final values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e94543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble final values into list\n",
    "ROI_values = [threat_threat_med, \n",
    "            threat_threat_iqr, \n",
    "            threat_control_med, \n",
    "            threat_control_iqr, \n",
    "            disc_rate, \n",
    "            disc_p_val]\n",
    "\n",
    "ROI_values.extend(ROI_rho_vals)\n",
    "ROI_values.extend(ROI_p_vals)\n",
    "\n",
    "ROI_value_labels = ['threat_threat_median', \n",
    "                    'threat_threat_iqr', \n",
    "                    'threat_control_median', \n",
    "                    'threat_control_iqr', \n",
    "                    'disc_rate', \n",
    "                    'disc_p_val',\n",
    "                    'rexp_r',\n",
    "                    'avoid_numb_r',\n",
    "                    'hyp_r',\n",
    "                    'rexp_p',\n",
    "                    'avoid_numb_p',\n",
    "                    'hyp_p']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
