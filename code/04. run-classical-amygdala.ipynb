{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d67baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined variables\n",
    "work_dir = '/Users/Tem/Documents/naturalistic-threat-ptsd'\n",
    "nPerms = 10000\n",
    "hemo_lag = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceced44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import iqr\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import fdrcorrection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c983f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to house classical figures\n",
    "date_string = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "classical_fig_dir = f\"{work_dir}/data/figures/classical-figs-{date_string}\"\n",
    "os.makedirs(classical_fig_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6542aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ROI labels\n",
    "amygdala_labels = pd.read_csv(f\"{work_dir}/masks/amygdala-harvard-oxford/ROI-labels.csv\")\n",
    "\n",
    "# Load and visualize symptom data\n",
    "CAPS_data = pd.read_csv(f\"{work_dir}/data/subs/CAPS.csv\")\n",
    "cohort_IDs = pd.read_csv(f\"{work_dir}/data/subs/cohort_IDs.csv\")\n",
    "nCohort = len(cohort_IDs)\n",
    "\n",
    "symptom_labels = ['Re-experiencing', 'Avoidance-Numbing', 'Hyperarousal']\n",
    "\n",
    "sns.heatmap(np.corrcoef(CAPS_data[symptom_labels].to_numpy(), rowvar = False), \n",
    "            xticklabels = symptom_labels,\n",
    "            yticklabels = symptom_labels,\n",
    "            annot = True)\n",
    "\n",
    "plt.yticks(rotation = 45)\n",
    "plt.xticks(rotation = 45, rotation_mode = 'anchor', ha = 'right') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3117b148",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function that correlates an interSC variable with each dimension of a symptom variable\n",
    "def corr_isc_symp(interSC_var, symp_var): \n",
    "    actual_corrs = [None] * len(symptom_labels)\n",
    "    corr_p_vals = [None] * len(symptom_labels)\n",
    "    all_null_dists = [None] * len(symptom_labels)\n",
    "    \n",
    "    for i in range(len(symptom_labels)):\n",
    "        which_score = symptom_labels[i]\n",
    "        null_dist = np.zeros(nPerms)\n",
    "\n",
    "        # Actual r value\n",
    "        x = symp_var[which_score]\n",
    "        y = interSC_var\n",
    "        actual_corr = stats.spearmanr(x, y)[0]\n",
    "        actual_corrs[i] = actual_corr\n",
    "\n",
    "        # Null distribution of r-values \n",
    "        for j in range(nPerms):\n",
    "            x = symp_var[which_score]\n",
    "            y = interSC_var[random.choices(range(nCohort), k = (nCohort))]\n",
    "            null_dist[j] = stats.spearmanr(x, y)[0]\n",
    "    \n",
    "        perms_above_frac = len((null_dist[null_dist > actual_corr]) + 1) / (nPerms + 1)\n",
    "        corr_p_vals[i] = min(2*perms_above_frac, 2*(1-perms_above_frac))\n",
    "        all_null_dists[i] = null_dist\n",
    "        \n",
    "    return actual_corrs, corr_p_vals, all_null_dists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407f68b",
   "metadata": {},
   "source": [
    "## Left Amygdala InterSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23066298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load event files for stimulus onsets\n",
    "all_CSminus_onsets = [None] * nCohort\n",
    "all_CSplus_onsets = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    day1_onsets = pd.read_csv(f\"{work_dir}/data/task/events-classical/{cohort_IDs['subject'][i]}.csv\")\n",
    "    \n",
    "    day1_CSplus = day1_onsets[day1_onsets['trial_type'].str.contains('plus') & ~day1_onsets['trial_type'].str.contains('US')].reset_index()\n",
    "    CSplus_onsets = [list(range(day1_CSplus['onset'][i] + hemo_lag, day1_CSplus['onset'][i] + day1_CSplus['duration'][i] + hemo_lag)) for i in range(len(day1_CSplus))]\n",
    "    all_CSplus_onsets[i] = [item for sublist in CSplus_onsets for item in sublist]\n",
    "\n",
    "    day1_CSminus = day1_onsets[day1_onsets['trial_type'].str.contains('minus')].reset_index()\n",
    "    CSminus_onsets = [list(range(day1_CSminus['onset'][i] + hemo_lag, day1_CSminus['onset'][i] + day1_CSminus['duration'][i] + hemo_lag)) for i in range(len(day1_CSminus))]\n",
    "    all_CSminus_onsets[i] = [item for sublist in CSminus_onsets for item in sublist]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ebb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute interSC \n",
    "disp_name = 'Left Amygdala'\n",
    "classical_data = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    classical_data[i] = np.load(work_dir +\n",
    "                                '/data/neural-classical/amygdala-harvard-oxford-6mm/HO_1_6mm/' +\n",
    "                                cohort_IDs['subject'][i] + '_6mm.npy')\n",
    "\n",
    "nVoxels = classical_data[0].shape[0]\n",
    "classical_patterns = np.zeros((nVoxels, 2, nCohort))\n",
    "\n",
    "for i in range(nCohort):\n",
    "    classical_patterns[:, 0, i] = np.mean(classical_data[i][:, all_CSminus_onsets[i]], axis = 1)\n",
    "    classical_patterns[:, 1, i] = np.mean(classical_data[i][:, all_CSplus_onsets[i]], axis = 1)\n",
    "    \n",
    "subs = np.arange(0, nCohort)\n",
    "classical_heldout = np.zeros_like(classical_patterns)\n",
    "    \n",
    "for i in subs:\n",
    "    sel_subs = subs[subs!= i]\n",
    "    classical_heldout[:, :, i] = np.mean(classical_patterns[:, :, sel_subs], axis = 2)\n",
    "    \n",
    "all_mats = np.zeros((2, 2, nCohort))\n",
    "LA_interSC = np.zeros((2, nCohort))\n",
    "\n",
    "for i in range(nCohort):\n",
    "    sub_mat = np.corrcoef(classical_patterns[:,:,i], classical_heldout[:,:,i], rowvar = False)\n",
    "    sub_mat = sub_mat[:2, 2:]\n",
    "    all_mats[:,:,i] = sub_mat\n",
    "    LA_interSC[:, i] = np.diagonal(sub_mat)\n",
    "\n",
    "\n",
    "# Visualize interSC \n",
    "sns.heatmap(np.median(all_mats, axis = 2),\n",
    "            yticklabels = ['CSminus-sub', 'CSplus-sub'],\n",
    "            xticklabels = ['CSminus-group', 'CSplus-group'],\n",
    "            annot = True)\n",
    "\n",
    "plt.title(disp_name, fontsize = 16)\n",
    "\n",
    "plt.yticks(rotation = 0)\n",
    "plt.xticks(rotation = 0) \n",
    "\n",
    "plt.savefig(f\"{classical_fig_dir}/isc_heatmap.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print median interSC values\n",
    "threat_control_isc = np.zeros(nCohort)\n",
    "threat_threat_isc = np.zeros(nCohort)\n",
    "\n",
    "for i in range(nCohort):\n",
    "    threat_control_isc[i] = all_mats[:,:,i][1,0]\n",
    "    threat_threat_isc[i] = all_mats[:,:,i][1,1]\n",
    "\n",
    "threat_threat_med = np.median(threat_threat_isc)\n",
    "threat_control_med = np.median(threat_control_isc)\n",
    "\n",
    "threat_threat_iqr = iqr(threat_threat_isc)\n",
    "threat_control_iqr = iqr(threat_control_isc)\n",
    "\n",
    "print('Threat-Threat')\n",
    "print(f\"median: {threat_threat_med}\")\n",
    "print(f\"iqr: {threat_threat_iqr}\")\n",
    "\n",
    "print('\\nThreat-Control')\n",
    "print(f\"median: {threat_control_med}\")\n",
    "print(f\"iqr: {threat_control_iqr}\")\n",
    "\n",
    "# Plot interSC values\n",
    "MvNM_data = pd.DataFrame({'InterSC': list(threat_threat_isc) + list(threat_control_isc),\n",
    "                          'ROI': ['L. Amygdala'] * nCohort*2,\n",
    "                          'Scene Type': ['Threat-Threat'] * len(threat_threat_isc) + ['Threat-Control'] * len(threat_control_isc)})\n",
    "\n",
    "colors = [\"#2d63f7\", \"#9ab4fc\"] # define colors for figure palette \n",
    "\n",
    "f = plt.figure(figsize=(12, 8))\n",
    "plt.subplot(131)\n",
    "\n",
    "ax = sns.boxplot(data = MvNM_data, \n",
    "            x = 'ROI', \n",
    "            y = 'InterSC', \n",
    "            hue = 'Scene Type', \n",
    "            linewidth = 2,\n",
    "            palette = sns.color_palette(colors))\n",
    "\n",
    "\n",
    "plt.xlabel(None)\n",
    "ax.tick_params(bottom = False)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend([],[], frameon = False)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f\"{classical_fig_dir}/MvNM_isc.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99dae2",
   "metadata": {},
   "source": [
    "## Discrimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate discrimination rate\n",
    "diff_scores = np.zeros(nCohort)\n",
    "for i in range(nCohort):\n",
    "    diff_scores[i] = threat_threat_isc[i] - threat_control_isc[i] \n",
    "    logical = diff_scores > 0\n",
    "disc_rate = sum(logical)/nCohort * 100\n",
    "\n",
    "# Generate null distribution\n",
    "null_dist_class = np.zeros(nPerms)\n",
    "\n",
    "for k in range(nPerms):\n",
    "\n",
    "    all_classical_patterns = np.zeros((nVoxels, 2, nCohort))\n",
    "\n",
    "    for i in range(nCohort):\n",
    "\n",
    "        concat_CS = np.asarray(all_CSminus_onsets[i] + all_CSplus_onsets[i])\n",
    "        break_point = len(all_CSminus_onsets[i])\n",
    "        concat_CS = concat_CS[random.choices(range(len(concat_CS)), k = (len(concat_CS)))]\n",
    "            \n",
    "        all_classical_patterns[:, 0, i] = np.mean(classical_data[i][:, concat_CS[:break_point]], axis = 1)\n",
    "        all_classical_patterns[:, 1, i] = np.mean(classical_data[i][:, concat_CS[break_point:]], axis = 1)\n",
    "\n",
    "    subs = np.arange(0, nCohort)\n",
    "    all_classical_heldout = np.zeros_like(all_classical_patterns)\n",
    "\n",
    "    for i in subs:\n",
    "        sel_subs = subs[subs!= i]\n",
    "        all_classical_heldout[:, :, i] = np.mean(all_classical_patterns[:, :, sel_subs], axis = 2)\n",
    "\n",
    "    all_mats = np.zeros((2, 2, nCohort))\n",
    "\n",
    "    for i in range(nCohort):\n",
    "        sub_mat = np.corrcoef(all_classical_patterns[:,:,i], all_classical_heldout[:,:,i], rowvar = False)\n",
    "        all_mats[:,:,i] = sub_mat[:2, 2:]\n",
    "        \n",
    "    # Discrimination\n",
    "    diff_scores = np.zeros(nCohort)\n",
    "\n",
    "    for i in range(nCohort):\n",
    "        shuff_threat_control_isc = all_mats[:,:,i][1,0]\n",
    "        shuff_isc_plus = all_mats[:,:,i][1,1]\n",
    "        diff_scores[i] = shuff_isc_plus - shuff_threat_control_isc \n",
    "        logical = diff_scores > 0\n",
    "    \n",
    "    null_dist_class[k] = (sum(logical)/nCohort * 100)\n",
    "    \n",
    "# Calculate p-value for classification accuracy\n",
    "disc_p_val = len((null_dist_class[null_dist_class > disc_rate]) + 1) / (nPerms + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display discrimination rate and p-value \n",
    "print(f\"discrimination rate = {np.round(disc_rate, 2)}%\")\n",
    "print(f\"discrimination p-value = {np.round(disc_p_val, 8)}\")\n",
    "\n",
    "f = plt.figure(figsize=(15, 5))\n",
    "sns.histplot(data = null_dist_class, color = '0.25', fill = False, element = 'step', bins = 30, linewidth = 3)\n",
    "plt.axvline(disc_rate, color = '#032a94', linewidth = 2.5)\n",
    "plt.axvline(np.mean(null_dist_class), color = '0.5', linestyle = 'dashed', linewidth = 2)\n",
    "plt.xticks(fontsize = 20)\n",
    "plt.yticks(fontsize = 20)\n",
    "plt.ylabel(None)\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig(f\"{classical_fig_dir}/discrimination_histogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2900e6",
   "metadata": {},
   "source": [
    "## Left Amygdala InterSC vs. Symptom Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c0957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate interSC with hyperarousal severity\n",
    "print(f\"{disp_name} Spatial InterSC vs. Hyperarousal \\n\")\n",
    "symptom_labels = ['Hyperarousal']\n",
    "LA_r_vals, LA_p_vals, LA_nulls =  corr_isc_symp(threat_threat_isc, CAPS_data)\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "summary['score'] = symptom_labels\n",
    "summary['r_vals'] = LA_r_vals\n",
    "summary['p_vals'] = LA_p_vals\n",
    "\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b27465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate interSC with all CAPS symptom severity\n",
    "print(f\"{disp_name} Spatial InterSC vs. All Symptoms \\n\")\n",
    "symptom_labels = ['Re-experiencing', 'Avoidance-Numbing', 'Hyperarousal']\n",
    "LA_r_vals, LA_p_vals, LA_nulls =  corr_isc_symp(threat_threat_isc, CAPS_data)\n",
    "\n",
    "summary = pd.DataFrame()\n",
    "summary['score'] = symptom_labels\n",
    "summary['r_vals'] = LA_r_vals\n",
    "summary['p_vals'] = LA_p_vals\n",
    "summary['p_corrected'] = fdrcorrection(LA_p_vals)[1]\n",
    "\n",
    "print(summary.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interSC vs. symptom severity\n",
    "f = plt.figure(figsize=(12, 5))\n",
    "f.suptitle('Left Amygdala Spatial InterSC vs. Symptom Severity', fontsize = 14)\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.25)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "\n",
    "ax1 = plt.subplot(131)\n",
    "x = CAPS_data['Hyperarousal']\n",
    "y = threat_threat_isc\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#032a94\"}).set(xlabel = '\\nHyperarousal Severity')\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "plt.ylabel('InterSC')\n",
    "\n",
    "ax2 = plt.subplot(132, sharey = ax1)\n",
    "x = CAPS_data['Avoidance-Numbing']\n",
    "y = threat_threat_isc\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#032a94\"}).set(xlabel = '\\nAvoidance-Numbing Severity')\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "\n",
    "ax3 = plt.subplot(133, sharey = ax1)\n",
    "x = CAPS_data['Re-experiencing']\n",
    "y = threat_threat_isc\n",
    "\n",
    "sns.regplot(x = x, y = y, scatter = False, line_kws = {\"color\": \"#032a94\"}).set(xlabel = '\\nRe-experiencing')\n",
    "plt.scatter(x, y, s = 50, facecolors = 'none', edgecolors = '0.2', linewidth = 1.5)\n",
    "\n",
    "plt.savefig(f\"{classical_fig_dir}/isc_v_symptoms.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
