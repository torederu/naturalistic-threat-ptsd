{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d093e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined working directory\n",
    "work_dir = '/Users/Tem/Documents/naturalistic-threat-ptsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b289edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "from nilearn import input_data\n",
    "from datetime import datetime\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.data import Brain_Data, Design_Matrix\n",
    "from nltools.stats import find_spikes \n",
    "from nltools.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f65a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load list of subIDs \n",
    "cohort_IDs = pd.read_csv(f\"{work_dir}/data/subs/cohort_IDs.csv\") \n",
    "sub_list = cohort_IDs['subject'].tolist()\n",
    "nCohort = len(sub_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda669b",
   "metadata": {},
   "source": [
    "## Smooth fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250846f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "unsmoothed_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-unsmoothed\" \n",
    "smoothed_output_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-smoothed-6mm\" \n",
    "fwhm = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth fMRI files\n",
    "if os.path.exists(smoothed_output_dir) == False:\n",
    "        os.makedirs(smoothed_output_dir)\n",
    "        print(f\"Created smoothed_output_dir: \\n{smoothed_output_dir}\")\n",
    "\n",
    "unsmoothed_list = os.listdir(f\"{unsmoothed_dir}\")\n",
    "unsmoothed_list = [x for x in unsmoothed_list if 'nii' in x]\n",
    "\n",
    "for i in unsmoothed_list:\n",
    "    subID = i.split('_')[0]\n",
    "    startTime = datetime.now()\n",
    "    unsmoothed_image = image.load_img(f\"{unsmoothed_dir}/{i}\")\n",
    "    smoothed_image = image.smooth_img(unsmoothed_image, fwhm = fwhm)\n",
    "    smoothed_image.to_filename(f\"{smoothed_output_dir}/{i}\")\n",
    "    print(f\"{subID} smoothing runtime = {datetime.now() - startTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534458db",
   "metadata": {},
   "source": [
    "## Generate design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "smoothed_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-smoothed-6mm\"\n",
    "confound_dir = f\"{work_dir}/data/neural-classical/confounds/raw-confounds\"\n",
    "dm_output_dir = f\"{work_dir}/data/neural-classical/confounds/dm-6mm\"\n",
    "outlier_cutoff = 3 #define outlier cutoff for despiking\n",
    "TR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61680edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of nifti and confound filenames\n",
    "exp_smoothed_dir = os.listdir(f\"{smoothed_dir}\")\n",
    "exp_confound_dir = os.listdir(f\"{confound_dir}\")\n",
    "\n",
    "smoothed_list = [None] * nCohort\n",
    "confound_list = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    smoothed_list[i] = [x for x in exp_smoothed_dir if sub_list[i] in x][0]\n",
    "    confound_list[i] = [x for x in exp_confound_dir if sub_list[i] in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc522cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load event files to generate condition regressors\n",
    "conditions_dm = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    confound_file = pd.read_csv(confound_dir + '/' + confound_list[i], delimiter = \"\\t\")\n",
    "    nTRs = len(confound_file)\n",
    "    event_df = pd.read_csv(f\"{work_dir}/data/task/events-classical/{sub_list[i]}.csv\")\n",
    "    event_df.columns = ['Stim', 'Onset', 'Duration']\n",
    "    events_df_wide = onsets_to_dm(event_df, sampling_freq = 1/TR, run_length = nTRs)\n",
    "    \n",
    "    CSminus_cols = [col for col in events_df_wide.columns if 'minus' in col]\n",
    "    CSplus_cols = [col for col in events_df_wide.columns if 'plus' in col and 'US' not in col]\n",
    "    US_cols = [col for col in events_df_wide.columns if 'US' in col]\n",
    "    \n",
    "    cond_regressors = pd.DataFrame({'CSminus': events_df_wide[CSminus_cols].sum(axis = 1),\n",
    "                                'CSplus': events_df_wide[CSplus_cols].sum(axis = 1),\n",
    "                                'US': events_df_wide[US_cols].sum(axis = 1)})\n",
    "    \n",
    "    conditions_dm[i] = Design_Matrix(cond_regressors, sampling_freq = 1/TR).convolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40f647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble full design matrices (with motion parameters) and save as tsv files \n",
    "if os.path.exists(dm_output_dir) == False:\n",
    "    os.makedirs(dm_output_dir)\n",
    "    print(f\"Created dm_output_dir: \\n{dm_output_dir}\\n\")\n",
    "    \n",
    "full_dms = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    print(sub_list[i])\n",
    "    \n",
    "    # Create BrainData object\n",
    "    print('creating braindata object...')\n",
    "    startTime = datetime.now()\n",
    "    smoothed_img = image.load_img(smoothed_dir + '/' + smoothed_list[i])\n",
    "    bd_func_img = Brain_Data(smoothed_img)\n",
    "    print(f\"braindata runtime = {datetime.now() - startTime}\\n\")\n",
    "    \n",
    "    # Identify spikes in fmri data\n",
    "    spikes = bd_func_img.find_spikes(global_spike_cutoff = outlier_cutoff, diff_spike_cutoff = outlier_cutoff)\n",
    "    spikes = spikes.drop(labels = 'TR', axis = 1)\n",
    "    \n",
    "    # Assemble fMRI regressors\n",
    "    fMRI_regressors = pd.read_csv(confound_dir + '/' + confound_list[i], delimiter = \"\\t\")\n",
    "    fMRI_regressors = fMRI_regressors[['global_signal', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']]\n",
    "    fMRI_regressors['intercept'] = 1\n",
    "    fMRI_regressors = Design_Matrix(pd.concat([fMRI_regressors, spikes], axis = 1), sampling_freq = 1/TR)\n",
    "    \n",
    "    # Assemble full design matrix\n",
    "    dm = pd.concat([conditions_dm[i], fMRI_regressors], axis = 1)\n",
    "    \n",
    "    # Save design matrix \n",
    "    full_dms[i] = dm\n",
    "    dm_output_file = f\"{dm_output_dir}/{sub_list[i]}_design-mat.tsv\"\n",
    "    dm.to_csv(dm_output_file, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc354e7",
   "metadata": {},
   "source": [
    "## Mask fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627b07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "mask_dir = f\"{work_dir}/masks/amygdala-harvard-oxford\"\n",
    "dm_dir = f\"{work_dir}/data/neural-classical/confounds/dm-6mm\"\n",
    "smoothed_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-smoothed-6mm\"\n",
    "npy_output_dir = f\"{work_dir}/data/neural-classical/masked/amygdala-harvard-oxford-6mm\"\n",
    "save_suffix = '_6mm' #suffix appended to npy fmri data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd0d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the ROIs to be masked \n",
    "ROI_mask_list = os.listdir(f\"{mask_dir}\")\n",
    "ROI_mask_list = [x for x in ROI_mask_list if 'nii' in x]\n",
    "nROIs = len(ROI_mask_list)\n",
    "\n",
    "print(ROI_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56f018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of nifti filenames\n",
    "exp_smoothed_dir = os.listdir(f\"{smoothed_dir}\")\n",
    "\n",
    "smoothed_list = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    smoothed_list[i] = [x for x in exp_smoothed_dir if sub_list[i] in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca057c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate masker objects\n",
    "all_maskers = [None] * len(ROI_mask_list)\n",
    "\n",
    "first_sub = sub_list[0]\n",
    "func_file = f\"{smoothed_dir}/{smoothed_list[0]}\"\n",
    "func_img = image.load_img(func_file)\n",
    "\n",
    "for i in range(nROIs):\n",
    "    mask_file = f\"{mask_dir}/{ROI_mask_list[i]}\"\n",
    "    mask_img = image.load_img(mask_file)\n",
    "    if mask_img.shape != func_img.shape[0:3]:\n",
    "        mask_img = image.resample_to_img(mask_img, func_img, interpolation = 'nearest')\n",
    "    all_maskers[i] = input_data.NiftiMasker(mask_img = mask_img, \n",
    "                                    mask_strategy = 'epi', \n",
    "                                    standardize = True,\n",
    "                                    detrend = True,\n",
    "                                    low_pass = 0.1,\n",
    "                                    high_pass = 0.01,\n",
    "                                    t_r = 1)\n",
    "    \n",
    "print(f\"Generated {i + 1} maskers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5095531e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask fMRI data for each subject using each mask and save masked data as npy arrays\n",
    "for i in range(nCohort):\n",
    "    func_file = image.load_img(smoothed_dir + '/' + smoothed_list[i])\n",
    "    confound_file = f\"{dm_dir}/{sub_list[i]}_design-mat.tsv\"\n",
    "    confound_df = pd.read_csv(confound_file, delimiter = \"\\t\")\n",
    "    \n",
    "    for j in range(nROIs):\n",
    "        cROI = ROI_mask_list[j][:-9]\n",
    "        if os.path.exists(f\"{npy_output_dir}/{cROI}_6mm/\") == False:\n",
    "            os.makedirs(f\"{npy_output_dir}/{cROI}_6mm/\")\n",
    "        cData = all_maskers[j].fit_transform(func_file, confounds = confound_df)\n",
    "        cData = np.transpose(cData, (1, 0))\n",
    "        np.save(f\"{npy_output_dir}/{cROI}_6mm/{sub_list[i]}_6mm\", cData)\n",
    "        \n",
    "    print(f\"done masking {sub_list[i]} data...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
