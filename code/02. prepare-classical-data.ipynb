{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11d093e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined working directory\n",
    "work_dir = '/Users/Tem/Documents/naturalistic-threat-ptsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b289edd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "from nilearn import input_data\n",
    "from datetime import datetime\n",
    "from nltools.file_reader import onsets_to_dm\n",
    "from nltools.data import Brain_Data, Design_Matrix\n",
    "from nltools.stats import find_spikes \n",
    "from nltools.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48f65a85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load list of subIDs \n",
    "cohort_IDs = pd.read_csv(f\"{work_dir}/data/subs/cohort_IDs.csv\") \n",
    "sub_list = cohort_IDs['subject'].tolist()\n",
    "nCohort = len(sub_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bda669b",
   "metadata": {},
   "source": [
    "## Smooth fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "250846f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "unsmoothed_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-unsmoothed\" \n",
    "smoothed_output_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-smoothed-6mm\" \n",
    "fwhm = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eeb357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-1319 smoothing runtime = 0:00:59.059628\n",
      "sub-1350 smoothing runtime = 0:00:55.429391\n",
      "sub-1389 smoothing runtime = 0:01:06.505295\n",
      "sub-1460 smoothing runtime = 0:01:02.675914\n",
      "sub-1359 smoothing runtime = 0:01:05.942899\n",
      "sub-1290 smoothing runtime = 0:01:04.393771\n",
      "sub-1271 smoothing runtime = 0:01:07.168521\n",
      "sub-1338 smoothing runtime = 0:01:04.254919\n",
      "sub-020 smoothing runtime = 0:01:13.411007\n",
      "sub-1301 smoothing runtime = 0:01:05.434561\n",
      "sub-1272 smoothing runtime = 0:01:02.505995\n",
      "sub-1303 smoothing runtime = 0:01:05.301995\n",
      "sub-1291 smoothing runtime = 0:01:01.454001\n",
      "sub-1374 smoothing runtime = 0:01:01.442915\n",
      "sub-1362 smoothing runtime = 0:01:03.436773\n",
      "sub-1343 smoothing runtime = 0:01:02.331152\n",
      "sub-1345 smoothing runtime = 0:01:04.390230\n",
      "sub-1347 smoothing runtime = 0:01:01.878111\n",
      "sub-1269 smoothing runtime = 0:01:02.072728\n",
      "sub-1379 smoothing runtime = 0:01:03.085858\n",
      "sub-1326 smoothing runtime = 0:01:00.943573\n",
      "sub-1320 smoothing runtime = 0:01:01.278560\n",
      "sub-1340 smoothing runtime = 0:01:04.065433\n",
      "sub-1005 smoothing runtime = 0:01:10.284755\n",
      "sub-1099 smoothing runtime = 0:01:06.316889\n",
      "sub-030 smoothing runtime = 0:01:02.850531\n",
      "sub-1072 smoothing runtime = 0:01:06.376303\n",
      "sub-1074 smoothing runtime = 0:00:57.658224\n",
      "sub-1205 smoothing runtime = 0:01:00.584521\n",
      "sub-1206 smoothing runtime = 0:01:04.229543\n",
      "sub-1220 smoothing runtime = 0:01:04.612514\n",
      "sub-1221 smoothing runtime = 0:01:02.845982\n",
      "sub-1237 smoothing runtime = 0:01:07.492327\n",
      "sub-1258 smoothing runtime = 0:01:06.250525\n",
      "sub-1309 smoothing runtime = 0:01:04.193446\n",
      "sub-1245 smoothing runtime = 0:01:00.668853\n",
      "sub-1223 smoothing runtime = 0:01:05.134835\n",
      "sub-029 smoothing runtime = 0:01:15.586477\n",
      "sub-1212 smoothing runtime = 0:00:59.963487\n",
      "sub-1254 smoothing runtime = 0:01:06.033716\n",
      "sub-1266 smoothing runtime = 0:01:03.848076\n",
      "sub-1268 smoothing runtime = 0:01:02.992222\n",
      "sub-1312 smoothing runtime = 0:01:02.934067\n",
      "sub-040 smoothing runtime = 0:01:09.315527\n",
      "sub-1210 smoothing runtime = 0:01:04.992078\n",
      "sub-1531 smoothing runtime = 0:01:05.522007\n",
      "sub-1538 smoothing runtime = 0:01:04.537717\n",
      "sub-1407 smoothing runtime = 0:01:04.636868\n"
     ]
    }
   ],
   "source": [
    "# Smooth fMRI files\n",
    "if os.path.exists(smoothed_output_dir) == False:\n",
    "        os.makedirs(smoothed_output_dir)\n",
    "        print(f\"Created smoothed_output_dir: \\n{smoothed_output_dir}\")\n",
    "\n",
    "unsmoothed_list = os.listdir(f\"{unsmoothed_dir}\")\n",
    "unsmoothed_list = [x for x in unsmoothed_list if 'nii' in x]\n",
    "\n",
    "for i in unsmoothed_list:\n",
    "    subID = i.split('_')[0]\n",
    "    startTime = datetime.now()\n",
    "    unsmoothed_image = image.load_img(f\"{unsmoothed_dir}/{i}\")\n",
    "    smoothed_image = image.smooth_img(unsmoothed_image, fwhm = fwhm)\n",
    "    smoothed_image.to_filename(f\"{smoothed_output_dir}/{i}\")\n",
    "    print(f\"{subID} smoothing runtime = {datetime.now() - startTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534458db",
   "metadata": {},
   "source": [
    "## Generate design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "096bc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "smoothed_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-smoothed-6mm\"\n",
    "confound_dir = f\"{work_dir}/data/neural-classical/confounds/raw-confounds\"\n",
    "dm_output_dir = f\"{work_dir}/data/neural-classical/confounds/dm-6mm\"\n",
    "outlier_cutoff = 3 #define outlier cutoff for despiking\n",
    "TR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61680edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of nifti and confound filenames\n",
    "exp_smoothed_dir = os.listdir(f\"{smoothed_dir}\")\n",
    "exp_confound_dir = os.listdir(f\"{confound_dir}\")\n",
    "\n",
    "smoothed_list = [None] * nCohort\n",
    "confound_list = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    smoothed_list[i] = [x for x in exp_smoothed_dir if sub_list[i] in x][0]\n",
    "    confound_list[i] = [x for x in exp_confound_dir if sub_list[i] in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dc522cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load event files to generate condition regressors\n",
    "conditions_dm = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    confound_file = pd.read_csv(confound_dir + '/' + confound_list[i], delimiter = \"\\t\")\n",
    "    nTRs = len(confound_file)\n",
    "    event_df = pd.read_csv(f\"{work_dir}/data/task/events-classical/{sub_list[i]}.csv\")\n",
    "    event_df.columns = ['Stim', 'Onset', 'Duration']\n",
    "    events_df_wide = onsets_to_dm(event_df, sampling_freq = 1/TR, run_length = nTRs)\n",
    "    \n",
    "    CSminus_cols = [col for col in events_df_wide.columns if 'minus' in col]\n",
    "    CSplus_cols = [col for col in events_df_wide.columns if 'plus' in col and 'US' not in col]\n",
    "    US_cols = [col for col in events_df_wide.columns if 'US' in col]\n",
    "    \n",
    "    cond_regressors = pd.DataFrame({'CSminus': events_df_wide[CSminus_cols].sum(axis = 1),\n",
    "                                'CSplus': events_df_wide[CSplus_cols].sum(axis = 1),\n",
    "                                'US': events_df_wide[US_cols].sum(axis = 1)})\n",
    "    \n",
    "    conditions_dm[i] = Design_Matrix(cond_regressors, sampling_freq = 1/TR).convolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40f647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub-020\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:40.005772\n",
      "\n",
      "sub-029\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:38.987976\n",
      "\n",
      "sub-030\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:24.872253\n",
      "\n",
      "sub-1005\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.117515\n",
      "\n",
      "sub-1072\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.891650\n",
      "\n",
      "sub-1074\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:18.734606\n",
      "\n",
      "sub-1099\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.510090\n",
      "\n",
      "sub-1205\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:24.210801\n",
      "\n",
      "sub-1206\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:25.574738\n",
      "\n",
      "sub-1210\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:24.957253\n",
      "\n",
      "sub-1212\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.259414\n",
      "\n",
      "sub-1220\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.690596\n",
      "\n",
      "sub-1221\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.814347\n",
      "\n",
      "sub-1223\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:29.560138\n",
      "\n",
      "sub-1237\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:03:08.092623\n",
      "\n",
      "sub-1245\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:03:02.182232\n",
      "\n",
      "sub-1254\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:03:04.232002\n",
      "\n",
      "sub-1258\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:03:05.409330\n",
      "\n",
      "sub-1266\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:03:03.623379\n",
      "\n",
      "sub-1268\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.689068\n",
      "\n",
      "sub-1269\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.559342\n",
      "\n",
      "sub-1271\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.894896\n",
      "\n",
      "sub-1272\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.827507\n",
      "\n",
      "sub-1290\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.648377\n",
      "\n",
      "sub-1291\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.069318\n",
      "\n",
      "sub-1301\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.478822\n",
      "\n",
      "sub-1303\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.047261\n",
      "\n",
      "sub-1309\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:25.883069\n",
      "\n",
      "sub-1312\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.743220\n",
      "\n",
      "sub-1319\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:21.219567\n",
      "\n",
      "sub-1320\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:22.401462\n",
      "\n",
      "sub-1326\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:24.165497\n",
      "\n",
      "sub-1338\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.822503\n",
      "\n",
      "sub-1340\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:25.341066\n",
      "\n",
      "sub-1345\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.459975\n",
      "\n",
      "sub-1347\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.294873\n",
      "\n",
      "sub-1350\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:18.193018\n",
      "\n",
      "sub-1359\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.451589\n",
      "\n",
      "sub-1362\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.320028\n",
      "\n",
      "sub-1374\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:29.562666\n",
      "\n",
      "sub-1379\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:25.676859\n",
      "\n",
      "sub-1389\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.587941\n",
      "\n",
      "sub-1407\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.178437\n",
      "\n",
      "sub-1460\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:26.471632\n",
      "\n",
      "sub-1531\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:27.290575\n",
      "\n",
      "sub-1538\n",
      "creating braindata object...\n",
      "BrainData runtime = 0:02:28.203829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assemble full design matrices (with motion parameters) and save as tsv files \n",
    "if os.path.exists(dm_output_dir) == False:\n",
    "    os.makedirs(dm_output_dir)\n",
    "    print(f\"Created dm_output_dir: \\n{dm_output_dir}\\n\")\n",
    "    \n",
    "full_dms = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    print(sub_list[i])\n",
    "    \n",
    "    # Create BrainData object\n",
    "    print('creating braindata object...')\n",
    "    startTime = datetime.now()\n",
    "    smoothed_img = image.load_img(smoothed_dir + '/' + smoothed_list[i])\n",
    "    bd_func_img = Brain_Data(smoothed_img)\n",
    "    print(f\"braindata runtime = {datetime.now() - startTime}\\n\")\n",
    "    \n",
    "    # Identify spikes in fmri data\n",
    "    spikes = bd_func_img.find_spikes(global_spike_cutoff = outlier_cutoff, diff_spike_cutoff = outlier_cutoff)\n",
    "    spikes = spikes.drop(labels = 'TR', axis = 1)\n",
    "    \n",
    "    # Assemble fMRI regressors\n",
    "    fMRI_regressors = pd.read_csv(confound_dir + '/' + confound_list[i], delimiter = \"\\t\")\n",
    "    fMRI_regressors = fMRI_regressors[['global_signal', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']]\n",
    "    fMRI_regressors['intercept'] = 1\n",
    "    fMRI_regressors = Design_Matrix(pd.concat([fMRI_regressors, spikes], axis = 1), sampling_freq = 1/TR)\n",
    "    \n",
    "    # Assemble full design matrix\n",
    "    dm = pd.concat([conditions_dm[i], fMRI_regressors], axis = 1)\n",
    "    \n",
    "    # Save design matrix \n",
    "    full_dms[i] = dm\n",
    "    dm_output_file = f\"{dm_output_dir}/{sub_list[i]}_design-mat.tsv\"\n",
    "    dm.to_csv(dm_output_file, sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc354e7",
   "metadata": {},
   "source": [
    "## Mask fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627b07ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "mask_dir = f\"{work_dir}/masks/amygdala-harvard-oxford\"\n",
    "dm_dir = f\"{work_dir}/data/neural-classical/confounds/dm-6mm\"\n",
    "smoothed_dir = f\"{work_dir}/data/neural-classical/niftis/classical-prepped-smoothed-6mm\"\n",
    "npy_output_dir = f\"{work_dir}/data/neural-classical/masked/amygdala-harvard-oxford-6mm\"\n",
    "save_suffix = '_6mm' #suffix appended to npy fmri data arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37fd0d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HO_1_mask.nii', 'HO_2_mask.nii']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of the ROIs to be masked \n",
    "ROI_mask_list = os.listdir(f\"{mask_dir}\")\n",
    "ROI_mask_list = [x for x in ROI_mask_list if 'nii' in x]\n",
    "nROIs = len(ROI_mask_list)\n",
    "\n",
    "print(ROI_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b56f018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of nifti filenames\n",
    "exp_smoothed_dir = os.listdir(f\"{smoothed_dir}\")\n",
    "\n",
    "smoothed_list = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    smoothed_list[i] = [x for x in exp_smoothed_dir if sub_list[i] in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca057c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2 maskers.\n"
     ]
    }
   ],
   "source": [
    "# Generate masker objects\n",
    "all_maskers = [None] * len(ROI_mask_list)\n",
    "\n",
    "first_sub = sub_list[0]\n",
    "func_file = f\"{smoothed_dir}/{smoothed_list[0]}\"\n",
    "func_img = image.load_img(func_file)\n",
    "\n",
    "for i in range(nROIs):\n",
    "    mask_file = f\"{mask_dir}/{ROI_mask_list[i]}\"\n",
    "    mask_img = image.load_img(mask_file)\n",
    "    if mask_img.shape != func_img.shape[0:3]:\n",
    "        mask_img = image.resample_to_img(mask_img, func_img, interpolation = 'nearest')\n",
    "    all_maskers[i] = input_data.NiftiMasker(mask_img = mask_img, \n",
    "                                    mask_strategy = 'epi', \n",
    "                                    standardize = True,\n",
    "                                    detrend = True,\n",
    "                                    low_pass = 0.1,\n",
    "                                    high_pass = 0.01,\n",
    "                                    t_r = 1)\n",
    "    \n",
    "print(f\"Generated {i + 1} maskers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5095531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done masking sub-020 data...\n",
      "done masking sub-029 data...\n",
      "done masking sub-030 data...\n",
      "done masking sub-1005 data...\n",
      "done masking sub-1072 data...\n",
      "done masking sub-1074 data...\n",
      "done masking sub-1099 data...\n",
      "done masking sub-1205 data...\n",
      "done masking sub-1206 data...\n",
      "done masking sub-1210 data...\n",
      "done masking sub-1212 data...\n",
      "done masking sub-1220 data...\n",
      "done masking sub-1221 data...\n",
      "done masking sub-1223 data...\n",
      "done masking sub-1237 data...\n",
      "done masking sub-1245 data...\n",
      "done masking sub-1254 data...\n",
      "done masking sub-1258 data...\n",
      "done masking sub-1266 data...\n",
      "done masking sub-1268 data...\n",
      "done masking sub-1269 data...\n",
      "done masking sub-1271 data...\n",
      "done masking sub-1272 data...\n",
      "done masking sub-1290 data...\n",
      "done masking sub-1291 data...\n",
      "done masking sub-1301 data...\n",
      "done masking sub-1303 data...\n",
      "done masking sub-1309 data...\n",
      "done masking sub-1312 data...\n",
      "done masking sub-1319 data...\n",
      "done masking sub-1320 data...\n",
      "done masking sub-1326 data...\n",
      "done masking sub-1338 data...\n",
      "done masking sub-1340 data...\n",
      "done masking sub-1345 data...\n",
      "done masking sub-1347 data...\n",
      "done masking sub-1350 data...\n",
      "done masking sub-1359 data...\n",
      "done masking sub-1362 data...\n",
      "done masking sub-1374 data...\n",
      "done masking sub-1379 data...\n",
      "done masking sub-1389 data...\n",
      "done masking sub-1407 data...\n",
      "done masking sub-1460 data...\n",
      "done masking sub-1531 data...\n",
      "done masking sub-1538 data...\n"
     ]
    }
   ],
   "source": [
    "# Mask fMRI data for each subject using each mask and save masked data as npy arrays\n",
    "for i in range(nCohort):\n",
    "    func_file = image.load_img(smoothed_dir + '/' + smoothed_list[i])\n",
    "    confound_file = f\"{dm_dir}/{sub_list[i]}_design-mat.tsv\"\n",
    "    confound_df = pd.read_csv(confound_file, delimiter = \"\\t\")\n",
    "    \n",
    "    for j in range(nROIs):\n",
    "        cROI = ROI_mask_list[j][:-9]\n",
    "        if os.path.exists(f\"{npy_output_dir}/{cROI}_6mm/\") == False:\n",
    "            os.makedirs(f\"{npy_output_dir}/{cROI}_6mm/\")\n",
    "        cData = all_maskers[j].fit_transform(func_file, confounds = confound_df)\n",
    "        cData = np.transpose(cData, (1, 0))\n",
    "        np.save(f\"{npy_output_dir}/{cROI}_6mm/{sub_list[i]}_6mm\", cData)\n",
    "        \n",
    "    print(f\"done masking {sub_list[i]} data...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
