{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b3805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined working directory\n",
    "work_dir = '/Users/Tem/Documents/naturalistic-threat-ptsd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb2eb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from nilearn import image\n",
    "from nilearn import input_data\n",
    "from datetime import datetime\n",
    "from nltools.data import Brain_Data, Design_Matrix\n",
    "from nltools.stats import find_spikes \n",
    "from nltools.stats import zscore\n",
    "import nibabel.imagestats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79fc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load list of subIDs \n",
    "cohort_IDs = pd.read_csv(f\"{work_dir}/data/subs/cohort_IDs.csv\") \n",
    "sub_list = cohort_IDs['subject'].tolist()\n",
    "nCohort = len(sub_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d8eb0",
   "metadata": {},
   "source": [
    "## Smooth fMRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c281d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "unsmoothed_dir = f\"{work_dir}/data/neural-naturalistic/niftis/naturalistic-prepped-unsmoothed\"\n",
    "smoothed_output_dir = f\"{work_dir}/data/neural-naturalistic/niftis/naturalistic-prepped-smoothed-6mm\" \n",
    "fwhm = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth fMRI files\n",
    "if os.path.exists(smoothed_output_dir) == False:\n",
    "    os.makedirs(smoothed_output_dir)\n",
    "    print(f\"Created smoothed_output_dir: \\n{smoothed_output_dir}\")\n",
    "\n",
    "unsmoothed_list = os.listdir(f\"{unsmoothed_dir}\")\n",
    "unsmoothed_list = [x for x in unsmoothed_list if 'nii' in x]\n",
    "\n",
    "for i in unsmoothed_list:\n",
    "    subID = i.split('_')[0]\n",
    "    startTime = datetime.now()\n",
    "    unsmoothed_image = image.load_img(f\"{unsmoothed_dir}/{i}\")\n",
    "    smoothed_image = image.smooth_img(unsmoothed_image, fwhm = fwhm)\n",
    "    smoothed_image.to_filename(f\"{smoothed_output_dir}/{i}.gz\")\n",
    "    print(f\"{subID} smoothing runtime = {datetime.now() - startTime}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af3b48",
   "metadata": {},
   "source": [
    "## Generate design matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables\n",
    "smoothed_dir = f\"{work_dir}/data/neural-naturalistic/niftis/naturalistic-prepped-smoothed-6mm\" \n",
    "confound_dir = f\"{work_dir}/data/neural-naturalistic/confounds/raw-confounds/\"\n",
    "dm_output_dir = f\"{work_dir}/data/neural-naturalistic/confounds/dm-6mm\" \n",
    "outlier_cutoff = 3 #define outlier cutoff for despiking\n",
    "TR = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0011f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of nifti and confound files\n",
    "exp_smoothed_dir = os.listdir(f\"{smoothed_dir}\")\n",
    "exp_confound_dir = os.listdir(f\"{confound_dir}\")\n",
    "\n",
    "smoothed_list = [None] * nCohort\n",
    "confound_list = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    smoothed_list[i] = [x for x in exp_smoothed_dir if sub_list[i] in x][0]\n",
    "    confound_list[i] = [x for x in exp_confound_dir if sub_list[i] in x][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe365d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble full design matrices (with motion parameters) and save as tsv files \n",
    "if os.path.exists(dm_output_dir) == False:\n",
    "    os.makedirs(dm_output_dir)\n",
    "    print(f\"Created dm_output_dir: \\n{dm_output_dir}\\n\")\n",
    "    \n",
    "full_dms = [None] * nCohort\n",
    "\n",
    "for i in range(nCohort):\n",
    "    \n",
    "    print(sub_list[i])\n",
    "    \n",
    "    # Create BrainData object\n",
    "    print('creating braindata object...')\n",
    "    startTime = datetime.now()\n",
    "    smoothed_img = image.load_img(smoothed_dir + '/' + smoothed_list[i])\n",
    "    bd_func_img = Brain_Data(smoothed_img)\n",
    "    print(f\"BrainData runtime = {datetime.now() - startTime}\")\n",
    "    \n",
    "    # Identify spikes in fmri data\n",
    "    spikes = bd_func_img.find_spikes(global_spike_cutoff = outlier_cutoff, diff_spike_cutoff = outlier_cutoff)\n",
    "    spikes = spikes.drop(labels = 'TR', axis = 1)\n",
    "    \n",
    "    # Create design matrix\n",
    "    covariates = pd.read_csv(confound_dir + '/' + confound_list[i], delimiter = \"\\t\")\n",
    "    covariates = covariates[['global_signal', 'trans_x', 'trans_y', 'trans_z', 'rot_x', 'rot_y', 'rot_z']]\n",
    "    covariates['intercept'] = 1\n",
    "    dm = Design_Matrix(pd.concat([covariates, spikes], axis = 1), sampling_freq = 1/TR)\n",
    "    \n",
    "    # Save design matrix \n",
    "    output_dm_filename = f\"{dm_output_dir}/{sub_list[i]}_design-mat.tsv\"\n",
    "    dm.to_csv(output_dm_filename, sep = '\\t', index = False)\n",
    "    print(f\"{sub_list[i]} design matrix runtime = {datetime.now() - startTime}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2626757",
   "metadata": {},
   "source": [
    "## Mask data by ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined variables\n",
    "mask_dir = f\"{work_dir}/masks/amygdala-harvard-oxford\"\n",
    "dm_dir = f\"{work_dir}/data/neural-naturalistic/confounds/dm-6mm\"\n",
    "smoothed_dir = f\"{work_dir}/data/neural-naturalistic/niftis/naturalistic-prepped-smoothed-6mm\"\n",
    "npy_output_dir = f\"{work_dir}/data/neural-naturalistic/niftis/masked/amygdala-harvard-oxford-6mm\"\n",
    "save_suffix = '_6mm_data'\n",
    "nTRs = 1020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d32275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to house output npy files\n",
    "if os.path.exists(npy_output_dir) == False:\n",
    "    os.makedirs(npy_output_dir)\n",
    "    print(f\"created {npy_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabdeeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the ROIs to be masked \n",
    "ROI_mask_list = os.listdir(f\"{mask_dir}\")\n",
    "ROI_mask_list = [x for x in ROI_mask_list if 'nii' in x]\n",
    "nROIs = len(ROI_mask_list)\n",
    "\n",
    "print(ROI_mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525df10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate masker objects\n",
    "all_maskers = [None] * len(ROI_mask_list)\n",
    "all_ROI_data = [None] * len(ROI_mask_list)\n",
    "\n",
    "first_sub = sub_list[0]\n",
    "func_file = f\"{smoothed_dir}/{first_sub}_prepped.nii.gz\"\n",
    "func_img = image.load_img(func_file)\n",
    "\n",
    "for i in range(len(ROI_mask_list)):\n",
    "    mask_img = image.load_img(f\"{mask_dir}/{ROI_mask_list[i]}\")\n",
    "    nVoxels = nibabel.imagestats.count_nonzero_voxels(mask_img)\n",
    "    if mask_img.shape != func_img.shape[0:3]:\n",
    "        mask_img = image.resample_to_img(mask_img, func_img, interpolation = 'nearest')\n",
    "    all_maskers[i] = input_data.NiftiMasker(mask_img = mask_img, \n",
    "                                    mask_strategy = 'epi', \n",
    "                                    standardize = True,\n",
    "                                    detrend = True,\n",
    "                                    low_pass = 0.1,\n",
    "                                    high_pass = 0.01,\n",
    "                                    t_r = 1)\n",
    "    all_ROI_data[i] = np.zeros([nTRs, nVoxels, nCohort])\n",
    "    \n",
    "print(f\"Generated {i + 1} maskers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask fMRI data for each subject using each mask\n",
    "for i in range(nCohort):\n",
    "    print(f\"Masking {sub_list[i]} data...\")\n",
    "    func_file = f\"{smoothed_dir}/{sub_list[i]}_prepped.nii.gz\"\n",
    "    func_img = image.load_img(func_file)\n",
    "    confound_file = f\"{dm_dir}/{sub_list[i]}_design-mat.tsv\"\n",
    "    confound_df = pd.read_csv(confound_file, delimiter = \"\\t\")[:nTRs]\n",
    "    \n",
    "    for j in range(len(ROI_mask_list)):\n",
    "        all_ROI_data[j][:, :, i] = all_maskers[j].fit_transform(func_img, confounds = confound_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb43a77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save masked data as npy arrays\n",
    "for i in range(len(ROI_mask_list)):\n",
    "    cROI = ROI_mask_list[i][:-9]\n",
    "    cData = all_ROI_data[i]\n",
    "    cData = np.transpose(cData, (1, 0, 2))\n",
    "    np.save(f\"{npy_output_dir}/{cROI}{save_suffix}\", cData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
